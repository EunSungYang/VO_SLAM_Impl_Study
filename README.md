# Visual Odometry / SLAM Implementations by MODULabs studies

## Authors: 
- [Hyunggi Chang, changh95 (study leader)](https://github.com/changh95)
-
-
-
-


## Background 

![modulabs](./Images/modu_logo.png)

This repository contains links to several repositories, which each repo contains individual efforts of implementing Visual Odometry (VO) or Visual-SLAM programs.
The authors of these repositories are the participants of the '슬기로운 SLAM 스터디' ('Wise SLAM study' in Korean) led by [Hyunggi Chang](https://github.com/changh95) with collaboration of [MODU Labs](https://home.modulabs.co.kr/).
Each participants aims to build computer vision applications to the best quality as they can, based on their skills and confidence. 

The suggested levels of implementation are as below:
- Newbie: Build a marker-based localization system
- Easy: Build a simple visual odometry system
- Medium: Build a visual odometry system, with bundle adjustment or factor graph representations
- Hard: Build a complex visual odometry or SLAM syste of your choice (recommended to implement loop closure, or deep-learning based frontend, or integrate IMU data)

The participant may freely choose the hardware or the dataset to be used for development and evaluation. 

## List of SLAM Implementation projects 

- {SAMPLE} [Hyunggi Chang](https://github.com/changh95) - [Accurate AR marker tracker with extended visual odometry, using monocular camera](https://www.google.com)
-
-
-
-
-
-
-
-
-
-
-
-
-
-